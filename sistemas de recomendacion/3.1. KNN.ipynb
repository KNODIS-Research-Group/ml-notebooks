{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.1. KNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"abIPUQ1LBeq_","colab_type":"text"},"source":["# Filtrado Colaborativo: *K-Nearest Neighbors*\n","\n","Los algoritmos de **filtrado colaborativo** basados en la técnica de los *k* vecinos (KNN) tratan de imitar el comportamiento de los seres humanos cuando buscan recibir una recomendación: cuando necesitamos conocer si nos va a interesar un item, preguntamos a personas que sabemos que conocen nuestros intereses si ellos consideran que el item nos va a gustar.\n","\n","El método realizará esta misma operación empleando la matriz de votaciones. Este proceso seguirá el siguiente algoritmo:\n","\n","1. Determinar la similaridad entre los usuarios\n","2. Encontrar el conjunto de *k* usuarios más similares (*k* vecinos)\n","3. Estimar las predicciones a los items no votados utilizando las votaciones realizadas por los *k* vecinos\n","4. (Opcional) Recomendar los *N* items con una predicción más alta\n","\n","En los siguientes subapartados explicaremos en detalle cada uno de estos pasos."]},{"cell_type":"markdown","metadata":{"id":"8uIM2LuLtg-B","colab_type":"text"},"source":["## Carga del dataset\n","\n","Para ilustrar mejor el funcionamiento de la técnica de KNN, vamos a desarrollar una implementación explicativa de cómo funciona. \n","\n","Para ello usaremos el dataset de [MovieLens 100K](https://grouplens.org/datasets/movielens/) que contiene 100.000 votos de 943 usuarios sobre 1682 películas. Este dataset ha sido dividido en votaciones de entrenamiento (80%) y votaciones de test (20%). Además, los códigos de usuarios e items, han sido modificados para que comience en 0 y terminen en el número de (usuarios / items) - 1.\n","\n","Inicialmente definimos algunas constantes que nos serán necesarias durante la codificación del algoritmo:"]},{"cell_type":"code","metadata":{"id":"9ChKXrFVw01m","colab_type":"code","colab":{}},"source":["import urllib\n","import math"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-X_ZhRdVwQci","colab_type":"code","colab":{}},"source":["NUM_USERS = 943\n","NUM_ITEMS = 1682\n","\n","MIN_RATING = 1\n","MAX_RATING = 5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iG-MLAXiv-kK","colab_type":"text"},"source":["Cargamos el dataset en la matriz de votaciones. La ausencia de voto se representa con None:"]},{"cell_type":"code","metadata":{"id":"Q1CTxoLABerB","colab_type":"code","colab":{}},"source":["ratings = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)] \n","\n","training_file = urllib.request.urlopen(\"https://drive.google.com/uc?export=view&id=1S4-sxOEvA3MDivaGf7iFirWqt1H6VtaH\")\n","for line in training_file:\n","  [u, i, rating] = line.decode(\"utf-8\").split(\"::\")\n","  ratings[int(u)][int(i)] = int(rating)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"52_CBchrzkoM","colab_type":"text"},"source":["Del mismo modo, cargamos la matriz de votaciones de test:"]},{"cell_type":"code","metadata":{"id":"Uo5dbgJMzsqd","colab_type":"code","colab":{}},"source":["test_ratings = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)] \n","\n","test_file = urllib.request.urlopen(\"https://drive.google.com/uc?export=view&id=1LBgTF57DD2NA-petq_FaC1V-h7nrYIh9\")\n","for line in test_file:\n","  [u, i, rating] = line.decode(\"utf-8\").split(\"::\")\n","  test_ratings[int(u)][int(i)] = int(rating)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XjZYIAKu8KRC","colab_type":"text"},"source":["Definimos también algunas funciones auxiliares que nos serán útiles:"]},{"cell_type":"code","metadata":{"id":"mf4LhvfN8R63","colab_type":"code","colab":{}},"source":["def rating_average (u):\n","  acc = 0\n","  count = 0\n","    \n","  for i in range(NUM_ITEMS):\n","    if ratings[u][i] != None:\n","      acc += ratings[u][i]\n","      count += 1\n","    \n","  avg = acc / count\n","    \n","  return avg"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vWbGQlXq0Bqg","colab_type":"text"},"source":["## Calculo de la similaridad\n","\n","El primer paso del algoritmo de KNN consiste en determinar el parecido de cada pareja de usuarios basándonos en las votaciones previas de dichos usuarios. Para calcular esta similaridad debemos tener presente que la matriz de votaciones es dispersa y, por lo tanto, parar comparar dos usuarios únicamente podremos emplear los votos sobre aquellos items que sean comunes a ambos usuarios.\n","\n","Por ejemplo, si un usuario *u* ha realizado las siguientes votaciones:\n","\n","|   \t| i1 \t| i2 \t| i3 \t| i4 \t| i5 \t| i6 \t| i7 \t| i8 \t| i9 \t| i10 \t|\n","|:-:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|-----\t|\n","| u \t|  1 \t|  2 \t|    \t|  4 \t|  2 \t|    \t|  3 \t|    \t|   \t|   5  \t|\n","\n","Y un usuario *v* ha realizado las siguientes votaciones:\n","\n","|   \t| i1 \t| i2 \t| i3 \t| i4 \t| i5 \t| i6 \t| i7 \t| i8 \t| i9 \t| i10 \t|\n","|:-:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|-----\t|\n","| v \t|  3 \t|   \t|  2  \t|   \t|  5 \t|  4  \t|  3 \t|  3  \t|   \t|  1 \t|\n","\n","Únicamente podremos comparar los votos producidos en los items *i1*, *i5*, *i7* e *i10*.\n","\n","Existen infinidad de métricas de similaridad que permiten conocer el parecido de dos usuarios en función de sus votos comunes. Las más tradicionales se basan en medidas estadísticas clásicas. Por ejemplo, una de las métricas más empleadas es la **correlación**:\n","\n","$$sim(u, v) = \\frac { \n","    \\sum_{i \\in I_{u,v}} (r_{u,i} - \\bar{r}_u)(r_{v,i} - \\bar{r}_v) \n","   } { \n","   \\sqrt{ \\sum_{i \\in I_{u,v}} (r_{u,i} - \\bar{r}_u)^2 \\sum_{i \\in I_{u,v}} (r_{v,i} - \\bar{r}_v)^2 } \n","   }$$\n","   \n","Donde $I_{u,v}$ representa los items que han votado tanto el usuario $u$ como el usuario $v$, $\\bar{r}_u$ representa la votación media del usuario $u$ y $\\bar{r}_v$ representa la votación media del usuario $v$."]},{"cell_type":"markdown","metadata":{"id":"qihZSD-P9Cj_","colab_type":"text"},"source":["La implementación de esta función podríamos hacerla del siguiente modo:"]},{"cell_type":"code","metadata":{"id":"r-mByaHh86np","colab_type":"code","colab":{}},"source":["def correlation_similarity (u, v):\n","  num = 0\n","  \n","  den_u = 0\n","  den_v = 0\n","  \n","  count = 0\n","  \n","  avg_u = rating_average(u)\n","  avg_v = rating_average(v)\n","  \n","  for i in range(NUM_ITEMS):\n","    if ratings[u][i] != None and ratings[v][i] != None:\n","      r_u = ratings[u][i]\n","      r_v = ratings[v][i]\n","      \n","      num += (r_u - avg_u) * (r_v - avg_v)\n","      den_u += (r_u - avg_u) * (r_u - avg_u)\n","      den_v += (r_v - avg_v) * (r_v - avg_v)\n","      \n","      count += 1\n","        \n","  if count > 0 and den_u != 0 and den_v != 0:    \n","    cor = num / math.sqrt( den_u * den_v )\n","    return cor;\n","  else:\n","    return None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tw-ss9cT-ryZ","colab_type":"text"},"source":["Aunque las métricas de similaridad basadas en medidas estadísticas clásicas ofrecen valores \"aceptables\" para el método de los *k* vecinos, existen otras métricas de similaridad específicas para el dominio del filtrado colaborativo. Una de las más populares es **JMSD** que permite calcular la similaridad atendiendo a dos factores: la información no numérica de los votos y la información numérica de los mismos. *JMSD* se define como el producto del índice de Jaccard por la diferencia cuadrática media:\n","\n","$$JMSD(u,v) = Jaccard(u,v) * (1 - MSD(u, v))$$\n","\n","El *índice de Jaccard* es una medida que permite comparar la similitud de dos conjuntos. En este caso se emplea para comprobar si los items votados por ambos usuarios coinciden, independientemente de la votación:\n","\n","$$Jaccard(u,v) =\\frac {I_u \\cap I_v} {I_u \\cup I_v} = \\frac {\\# \\{ i \\in I | r_{u,i} \\neq \\bullet \\wedge r_{v,i} \\neq \\bullet \\}} {\\# \\{ i \\in I | r_{u,i} \\neq \\bullet \\vee r_{v,i} \\neq \\bullet \\}}$$\n","\n","Donde $I_u$ representa los items votados por el usuario $u$ e $I_v$ representa los items votados por el usuario $v$.\n","\n","El *MSD* permite comparar si los usuarios tienen la misma opinión sobre los items que votaron en común. En este caso, el *MSD* retorna el valor 0 cuando los usuarios votaron idéntico, por lo que suele invertirse para lograr que cuanto más se parezcan dos usuarios, mayor sea su similaridad. Para esto, es necesario normalizar previamente las votaciones:\n","\n","$$MSD(u,v) = \\frac {1} {\\#I_{u,v}} \\sum_{i \\in I_{u,v}} (r_{u,i} - r_{v,i})^2$$\n","\n","Donde $I_{u,v}$ representa los items votados en común por $u$ y $v$.\n","\n","Esta medida busca un equilibrio entre los items que los dos usuarios han votado y lo parecidas que son estas votaciones."]},{"cell_type":"markdown","metadata":{"id":"YGDVaMakQvqZ","colab_type":"text"},"source":["La implementación de esta función podríamos hacerla del siguiente modo:"]},{"cell_type":"code","metadata":{"id":"IX0FmAFLQwYu","colab_type":"code","colab":{}},"source":["def jmsd_similarity (u, v):\n","  \n","  union = 0\n","  intersection = 0\n","  diff = 0\n","  \n","  for i in range(NUM_ITEMS):\n","    if ratings[u][i] != None and ratings[v][i] != None:\n","      r_u = (ratings[u][i] - MIN_RATING) / (MAX_RATING - MIN_RATING)\n","      r_v = (ratings[v][i] - MIN_RATING) / (MAX_RATING - MIN_RATING)\n","      \n","      diff = (r_u - r_v) * (r_u - r_v)\n","      \n","      intersection += 1\n","      union += 1 \n","      \n","    elif ratings[u][i] != None or ratings[v][i] != None:  \n","      union += 1\n","\n","        \n","  if intersection > 0:\n","    jaccard = intersection / union\n","    msd = diff / intersection\n","    return jaccard * (1 - msd);\n","  else:\n","    return None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DWqaPSYGBerF","colab_type":"text"},"source":["## Búsqueda de los *k* vecinos\n","\n","En el método de KNN, las predicciones se realizan a partir del conjunto de *k* vecinos de cada usuario, esto es, el conjunto de *k* usuarios más similares a uno dado. Este *k* será considerado como un parámetro del sistema y deberá tunearse para cada dataset. \n","\n","La búsqueda de los *k* vecinos consiste únicamente en ordenar los usuarios en base a su similaridad y elegir a los *k* con una similaridad más alta."]},{"cell_type":"markdown","metadata":{"id":"DEmVC4XMRone","colab_type":"text"},"source":["La implementación de esta función podríamos hacerla del siguiente modo:"]},{"cell_type":"code","metadata":{"id":"6rInkOjwRpN_","colab_type":"code","colab":{}},"source":["k = 25"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-uNjyly9RxSl","colab_type":"code","colab":{}},"source":["def get_neighbors (u, similarities):\n","  \n","  neighbors = [None for _ in range(k)]\n","  \n","  for n in range(k):\n","    \n","    max_similarity = 0\n","    neighbor = None\n","    \n","    for v, sim in enumerate(similarities):\n","      if v not in neighbors and sim != None and sim > max_similarity:\n","        max_similarity = sim\n","        neighbor = v\n","    \n","    neighbors[n] = neighbor\n","\n","    return neighbors"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_qXQqvwVTQgm","colab_type":"text"},"source":["## Estimación de las predicciones\n","\n","La estimación de las predicciones se realiza agregando las votaciones que los *k* vecinos del usuario activo realizaron al item que se quiere predecir. De nuevo, nos encontramos con el problema de la dispersión de la matriz de votaciones, ya que no todos los *k* vecinos habrá votado los mismos items. Podría incluso darse la circunstancia de que un item no hubiera sido votado por ninguno de los *k* vecinos y, por tanto, no podría estimarse una predicción. \n","\n","Esta situación puede ayudarnos a tunear el parámetro *k*. Si elegimos un *k* muy bajo conseguimos predicciones precisas ya que se realizar con usuarios muy similares al activo, pero existirán muchos items que no podremos predecir. Si elegimos un *k* muy elevado podremos predecir casi todos los items pero estas predicciones serán poco personalizadas. Llevado al extremo si *k* es igual al número de usuario del sistema (menos uno), las predicciones serían equivalentes a la media de los votos.\n","\n","Existen diversas formas de agregar las votaciones de los *k* vecinos (*aggregation approach*), aunque, la más popular debido a su sencillez es la media:\n","\n","$$\\hat{r}_{u,i} = \\frac{1}{\\#N_{u,i}} \\sum_{n \\in N_{u,i}} r_{n,i}$$\n","\n","Donde $N_{u,i}$ representa el conjunto de *k* vecinos del usuario $u$ que votaron el item $i$."]},{"cell_type":"markdown","metadata":{"id":"G3I1eqP2Zivy","colab_type":"text"},"source":["La implementación de esta medida de agregación podríamos hacerla del siguiente modo:"]},{"cell_type":"code","metadata":{"id":"z5SHyUMOZl1A","colab_type":"code","colab":{}},"source":["def average_prediction (u, i, neighbors):\n","  acc = 0\n","  count = 0\n","  \n","  for n in neighbors:\n","    if n == None: break\n","      \n","    if ratings[n][i] != None:\n","      acc += ratings[n][i]\n","      count += 1\n","  \n","  if count > 0:\n","    prediction = acc / count\n","    return prediction\n","  else:\n","    return None\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qMGJlXIL6bOK","colab_type":"text"},"source":["Una evolución simple de esta medida de agregación es la media ponderada, en la cual el voto de cada uno de los vecinos se pondera en función de su similaridad con el usuario sobre el que se está calculando la predicción:\n","\n","$$\\hat{r}_{u,i} = \\frac{\\sum_{n \\in N_{u,i}} sim(u,n) \\cdot r_{n,i}}{\\sum_{n \\in N_{u,i}} sim(u,n)} $$\n","\n","Donde $N_{u,i}$ representa el conjunto de *k* vecinos del usuario $u$ que votaron el item $i$ y $sim(u,n)$ simboliza la similaridad entre el usuario $u$ y el vecino $n$."]},{"cell_type":"code","metadata":{"id":"VZLaWCTH7OYc","colab_type":"code","colab":{}},"source":["def weighted_average_prediction (u, i, neighbors, similarities):\n","  num = 0\n","  den = 0\n","  \n","  for n in neighbors:\n","    if n == None: break\n","      \n","    if ratings[n][i] != None:\n","      num += similarities[n] * ratings[n][i]\n","      den += similarities[n]\n","  \n","  if den > 0:\n","    prediction = num / den\n","    return prediction\n","  else:\n","    return None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pt_lN0V3afJT","colab_type":"text"},"source":["Utilizar la media o la media ponderada como medida de agregación tiene un problema, presupone que todos los usuarios tienen la misma percepción de la escala de votaciones prefijada. Sin embargo, sabemos que esto no es cierto. Existes determinados sesgos que hacen que los usuarios realicen votaciones haciendo una interpretación particular del sentido de su voto. Por ejemplo, existen usuarios más \"generosos\" con las votaciones que tienden a asignar siempre valoraciones altas y existen usuarios más \"tacaños\" con las votaciones que tienden a asignar siempre valoraciones más bajas. Que el primer usuario valore un item con 5 y el segundo usuario valore el mismo item con un 4 no quiere decir que al primero le haya gustado más el item. Cada usuario hace su propia interpretación de lo que significan los votos 4 y 5.\n","\n","Para incluir este fenómeno dentro de las medidas de agregación, es frecuente agregar las votaciones de los k vecinos mediante la **desviación respecto a la media** (*deviation from mean*):\n","\n","$$\\hat{r}_{u,i} = \\bar{r}_{u} + \\frac{ \\sum_{n \\in N_{u,i}} r_{n,i} - \\bar{r}_n }{\\#N_{u,i}}$$\n","\n","Donde $N_{u,i}$ representa el conjunto de *k* vecinos del usuario $u$ que votaron el item $i$, $\\bar{r}_u$ representa la media de votos del usuario $u$ y $\\bar{r}_n$ representa la media de votos del usuario $n$."]},{"cell_type":"markdown","metadata":{"id":"lFrM3nbkcGQ9","colab_type":"text"},"source":["La implementación de esta medida de agregación podríamos hacerla del siguiente modo:"]},{"cell_type":"code","metadata":{"id":"IzGbdNPkcHF1","colab_type":"code","colab":{}},"source":["def deviation_from_mean_prediction (u, i, neighbors):\n","  acc = 0\n","  count = 0\n","  \n","  for n in neighbors:\n","    if n == None: break\n","      \n","    if ratings[n][i] != None:\n","      avg_n = rating_average(n)\n","      acc += ratings[n][i] - avg_n\n","      count += 1\n","  \n","  if count > 0:\n","    avg_u = rating_average(u)\n","    prediction = avg_u + acc / count\n","    return prediction\n","  else:\n","    return None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Wz44ClHcgZy","colab_type":"text"},"source":["## Cálculo de las recomendaciones\n","\n","El cálculo de las recomendaciones, por lo general, simplemente implica seleccionar los *N* items con una predicción más alta. Por ejemplo, si quisiéramos recomendar *N = 3* items a un usuario que tuviera las siguientes predicciones:\n","\n","|   \t| i1 \t| i2 \t| i3 \t| i4 \t| i5 \t| i6 \t| i7 \t| i8 \t| i9 \t| i10 \t|\n","|:-:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|-----\t|\n","| u \t|   \t|  2,9 \t|    \t|  4,7 \t|  5,0 \t|    \t|  1,2 \t|    \t|   \t|  3,1 \t|\n","\n","Se le recomendarían a dicho usuario los items *i5*, *i4* e *i10*.\n","\n","En algunas ocasiones, es posible establecer filtros para acotar los items a recomendar. Por ejemplo: en un sistema de recomendación de restaurantes, es posible filtrar aquellos items que se encuentren a demasiada distancia del usuarios; en un sistema de recomendación de libros, el usuario puede filtrar el idioma o el género literario del libro; en una web de comercio electrónico es posible realizar recomendaciones sobre una categoría concreta...\n"]},{"cell_type":"markdown","metadata":{"id":"dkjnWQAXci_w","colab_type":"text"},"source":["##Ejemplo de ejecución: cálculo del MAE\n","\n","En esta sección vamos a mostrar el ejemplo completo de cómo calcular el error medio absoluto (MAE) de las predicciones realizadas por el método de los *k*-vecinos.\n","\n","Para ello, lo primero que debemos hacer es calcular las predicciones para todos los items que haya recibido una votación de test:"]},{"cell_type":"code","metadata":{"id":"O-weSAoCf54x","colab_type":"code","colab":{}},"source":["def has_test_ratings (u):\n","  for i in range(NUM_ITEMS):\n","    if test_ratings[u][i] != None:\n","      return True\n","  return False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DUFHu__JhZh","colab_type":"code","colab":{}},"source":["predictions = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)] \n","\n","# Rellenamos la matriz de predicciones\n","for u in range(NUM_USERS):\n","  if has_test_ratings(u):\n","    \n","    # Calcular similaridades\n","    similarities = [None for _ in range(NUM_USERS)]\n","    for v in range(NUM_USERS):\n","      #sim = None if u == v else correlation_similarity(u, v) \n","      sim = None if u == v else jmsd_similarity(u, v) \n","      similarities[v] = sim\n","      \n","    # Calcular vecinos\n","    neighbors = get_neighbors(u, similarities)\n","    \n","    # Calcular predicciones sobre los items de test votados por el usuario\n","    for i in range(NUM_ITEMS):\n","      if test_ratings[u][i] != None:\n","        predictions[u][i] = average_prediction(u, i, neighbors)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aY9mSfJ8JiFk","colab_type":"text"},"source":["Y, a continuación, calculamos el MAE:"]},{"cell_type":"code","metadata":{"id":"EbO4UNuAbYAi","colab_type":"code","colab":{}},"source":["def get_user_mae (u):\n","  mae = 0\n","  count = 0\n","  \n","  for i in range(NUM_ITEMS):\n","    if test_ratings[u][i] != None and predictions[u][i] != None:\n","      mae += abs(test_ratings[u][i] - predictions[u][i])\n","      count += 1\n","  \n","  if count > 0:\n","    return mae / count\n","  else:\n","    return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iWWoWTpObMun","colab_type":"code","colab":{}},"source":["def get_mae ():\n","  mae = 0\n","  count = 0\n","  \n","  for u in range(NUM_USERS):\n","    if has_test_ratings(u):\n","      user_mae = get_user_mae(u)\n","      \n","      if user_mae != None:\n","        mae += user_mae\n","        count += 1\n","  \n","  \n","  if count > 0:\n","    return mae / count\n","  else:\n","    return None   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WUnIY4ExETZ1","colab_type":"code","outputId":"cf553c52-51b1-4739-800f-3800bf85f409","executionInfo":{"status":"ok","timestamp":1553528336934,"user_tz":-60,"elapsed":94416,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh5.googleusercontent.com/-t9XtZoyOrPU/AAAAAAAAAAI/AAAAAAAAA2I/muQCKCLOQqk/s64/photo.jpg","userId":"02003917424124170753"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mae = get_mae()\n","print(\"System MAE = \" + str(mae))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["System MAE = 0.8773974867724869\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gOzPrmkoXGea","colab_type":"text"},"source":["## Referencias\n","\n","Bobadilla, J., Serradilla, F., & Bernal, J. (2010). **A new collaborative filtering metric that improves the behavior of recommender systems**. Knowledge-Based Systems, 23(6), 520-528."]},{"cell_type":"markdown","metadata":{"id":"NWfEvBgpfyvq","colab_type":"text"},"source":["---\n","\n","*Este documento ha sido desarrollado por **Fernando Ortega**. Dpto. Sistemas Informáticos, ETSI de Sistemas Informáticos, Universidad Politécnica de Madrid.*\n","\n","*Última actualización: Marzo de 2019*\n"]},{"cell_type":"markdown","metadata":{"id":"g5180Pds-8VP","colab_type":"text"},"source":["<img src=\"https://drive.google.com/uc?export=view&id=1QuQDHyH_yrRbNt6sGzoZ8YcvFGEGlnWZ\" alt=\"CC BY-NC\">"]}]}