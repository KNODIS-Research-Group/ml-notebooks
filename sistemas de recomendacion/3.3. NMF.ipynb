{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.3. NMF.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"DM9cd2i-ufBX","colab_type":"text"},"source":["# Filtrado Colaborativo: *Non-negative Matrix Factorization*\n","\n","El filtrado colaborativo basado en factorización matricial proporciona unos resultados excelentes en cuanto a calidad de predicciones y recomendaciones. Además, permite resolver el problema de la escalabilidad, puesto que, una vez aprendido el modelo, el cálculo de las predicciones se realiza en un tiempo ínfimo. \n","\n","Sin embargo, el algoritmo PMF tiene una deficiencia: la transformación de la matriz de votaciones en matrices de factores latentes es altamente abstracta para los usuarios y, por ende, imposibilita la explicación de las recomendaciones. Los modelos de KNN proporcionaban unas predicciones poco certeras y no escalaban bien, pero la explicación de dichas predicciones era muy sencilla: \"*votarás este item con esta nota ya que estos usuarios que tienen intereses similares a los tuyos lo han votado así*\". Sin embargo, PMF realiza las predicciones atendiendo a los factores latentes. ¿Qué significado tienen estos factores? ¿Qué quiere decir que un usuario tiene el factor 3 con un valor de 0,34? ¿Y que un item tiene el factor 8 con -4,06? Es complicado de explicar.\n","\n","No poder explicar las recomendaciones provoca la desconfianza del usuario hacia el sistema. En general, los usuarios necesitan conocer el porqué de las cosas. Además, si se produce una predicción acertada y se explica dicha predicción, la satisfacción del usuario es doble. Igualmente, si se falla una predicción, pero se justifica correctamente, el usuario suele ser benevolente con el sistema.\n","\n","La principal problematica de los factores latentes, más allá de su alto nivel de abstracción, es la inclusión de factores negativos dentro del modelo de fatorización matricial. Parece razonable justificar que las vataciones se encuentran condicionadas por una serie de factores / características / propiedades intrínsecas de los usuarios e items en un dominio concreto. Por ejemplo, indicar que te gustará una películas porque mezcla los genéros acción y comedia es una justificación comprensible. Sin embargo, tener factores con valores negativos hace imposible este tipo de justificaciones. ¿Que un factor valga 0,25 y otro valga -0,31 indica que el primero es afín y el segundo no? No necesariamente.\n","\n","El modelo *NMF (**Non-negative Matrix Factorization**)*, al igual que otros algoritmos de factorización matricial, factoriza la matriz de votaciones $R$ en dos nuevas matrices $W$ y $H$ tales que verifiquen la siguiente expresión:\n","\n","$$R \\approx W \\cdot H$$\n","\n","De forma análoga a como sucedía en PMF, en esta expresión:\n","\n","- $R$ representa la matriz (dispersa) con las votaciones de los usuarios (filas) a los items (columnas).\n","- $W$ representa las matriz (densa) de factores de los usuarios (filas) con los $k$ factores latentes (columnas).\n","- $H$ representa las matriz (densa) de factores de los items (columnas) con los $k$ factores latentes (filas).\n","\n","Por lo tanto, el algoritmo NMF tratará de minimizar la diferencia cuadrática entre $R$ y $W \\cdot H$, mediante la siguiente función de coste:\n","\n","$$\\sum_{u,i} (R_{u,i} - (W \\cdot H)_{u,i})^2$$\n","\n","Con el fin de facilitar las justificación de los resultados proporcionados por el modelo, añadimos una restricción adicional: **los valores de las matrices $W$ y $H$ deben ser siempre mayores o iguales a 0**.\n","\n","La resolución de este problema podríamos plantearla mediante la ténica del descenso de gradiente, tal y como hicimos con PMF, sin embargo, la restricción de valores positivos permite transformar la función de coste para acelerar el proceso de aprendizaje. Para ello debemos considerar que esta función de coste es convexa únicamente en $W$ o en $H$, no en las dos funciones al mismo tiempo, por lo que se optimizará una de las matrices fijando la otra y, a continuación, se hará la operación inversa.\n","\n","Partiendo de esta premisa, cuando estamos aplicando el método de descenso de gradiente, optimizar una matriz $A$ en la interación $n$ implica aplicar una actualización $U_n$ a los valores que la matriz $A$ tenía en la iteración $n-1$. En concreto, los valores de la actualización se corresponden con la inversa del gradiente de la función de coste.\n","\n","$$A_n \\leftarrow A_{n-1} + U_n $$\n","\n","Sabiendo que en NMF los valores de esta matriz son siempre positivos podemos optar por optimizar la exponencial de la función de coste en lugar de la propia función de coste, ya que la función exponencial es una función monótona creciente.\n","\n","Si definimos:\n","\n","$$B = exp(A)$$\n","\n","Podemos deducir que:\n","\n","$$B_n = exp(A_n) = exp(A_{n-1} + U_n) = exp(A_{n-1}) \\cdot exp(U_n) = B_{n-1} \\cdot exp(U_n)$$\n","\n","Aplicando este proceso a la función de coste utilizada por NMF, obtenemos las siguientes reglas de actualización de las matrices $W$ y $H$:\n","\n","$$W \\leftarrow W \\cdot \\frac{R \\cdot H^T}{W \\cdot H \\cdot H^T}$$\n","\n","$$H \\leftarrow H \\cdot \\frac{W^T \\cdot R}{W \\cdot W^T \\cdot H}$$\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WlQR5g2CntZT","colab_type":"text"},"source":["## Entrenamiento del modelo\n","\n","Desarrollando las operaciones matriciales anteriores, podemos determinar las ecuación de actualización de los factores de los usuarios ($w_u$) y los items ($h_i$) que permiten optimizar las matrices $W$ y $H$ alternativamente hasta la convergencia.\n","\n","La actualización del factor *k*-ésimo del usuario $u$ se hará de acuerdo a la siguiente ecuación:\n","\n","$$w_{u,k} = w_{u,k} \\cdot \\frac{\\sum_{i \\in I_u} h_{i,k} \\cdot r_{u,i}}{\\sum_{i \\in I_u} h_{i,k} \\cdot \\sum_{l=1}^K w_{u,l} * h_{i,l}}$$\n","\n","Dónde $I_u$ denota los items votados por el usuario $u$ y $K$ simboliza el número de factores del modelo.\n","\n","Por su parte, la actualización del factor *k*-ésimo del item $i$ se hará de acuerdo a la siguiente ecuación:\n","\n","$$h_{i,k} = h_{i,k} \\cdot \\frac{\\sum_{u \\in U_i} w_{u,k} \\cdot r_{u,i}}{\\sum_{u \\in U_i} w_{u,k} \\cdot \\sum_{l=1}^K w_{u,l} \\cdot h_{i,l}}$$\n","\n","Dónde $U_i$ denota los usuarios que han votado el item $i$ y $K$ simboliza el número de factores del modelo.\n","\n","Podemos simplificar las ecuaciones anteriores puesto que la predicción del voto del usuario $u$ al item $i$ ($\\hat{r}_{u,i}$) se calcula como el producto escalar de los factores del usuario $u$ y el item $i$:\n","\n","$$\\hat{r}_{u,i} = \\sum_{k=1}^K w_{u,k} \\cdot h_{i,k}$$\n","\n","De este modo la actualización del factor *k*-ésimo del usuario $u$ se hará de acuerdo a la siguiente ecuación:\n","\n","$$w_{u,k} = w_{u,k} \\cdot \\frac{\\sum_{i \\in I_u} h_{i,k} \\cdot r_{u,i}}{\\sum_{i \\in I_u} h_{i,k} \\cdot \\hat{r}_{u,i}}$$\n","\n","Mientras que la actualización del factor *k*-ésimo del item $i$ se hará de acuerdo a la siguiente ecuación:\n","\n","$$h_{i,k} = h_{i,k} \\cdot \\frac{\\sum_{u \\in U_i} w_{u,k} \\cdot r_{u,i}}{\\sum_{u \\in U_i} w_{u,k} \\cdot \\hat{r}_{u,i}}$$\n","\n","Veamos cómo hacer esto con código.\n"]},{"cell_type":"markdown","metadata":{"id":"YZSFkDqsuLes","colab_type":"text"},"source":["## Carga del dataset\n","\n","Para ilustrar mejor el funcionamiento el algoritmo NMF, vamos a desarrollar una implementación del mismo.\n","\n","Para ello usaremos el dataset de [MovieLens 100K](https://grouplens.org/datasets/movielens/) que contiene 100.000 votos de 943 usuarios sobre 1682 películas. Este dataset ha sido dividido en votaciones de entrenamiento (80%) y votaciones de test (20%). Además, los códigos de usuarios e items, han sido modificados para que comience en 0 y terminen en el número de (usuarios / items) - 1.\n"]},{"cell_type":"markdown","metadata":{"id":"9yhGC0WIuORP","colab_type":"text"},"source":["Inicialmente definimos algunas constantes que nos serán necesarias durante la codificación del algoritmo:"]},{"cell_type":"code","metadata":{"id":"7pXAbayjuSqc","colab_type":"code","colab":{}},"source":["import urllib\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tNuX_hVEuQe5","colab_type":"code","colab":{}},"source":["NUM_USERS = 943\n","NUM_ITEMS = 1682\n","\n","MIN_RATING = 1\n","MAX_RATING = 5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ycfkDZZDuVkq","colab_type":"text"},"source":["Y cargamos el dataset:"]},{"cell_type":"code","metadata":{"id":"C7S5kGa1uSKU","colab_type":"code","colab":{}},"source":["ratings = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)] \n","\n","training_file = urllib.request.urlopen(\"https://drive.google.com/uc?export=view&id=1S4-sxOEvA3MDivaGf7iFirWqt1H6VtaH\")\n","for line in training_file:\n","  [u, i, rating] = line.decode(\"utf-8\").split(\"::\")\n","  ratings[int(u)][int(i)] = int(rating)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qr4uRdaqua7Q","colab_type":"text"},"source":["Del mismo modo, cargamos la matriz de votaciones de test:"]},{"cell_type":"code","metadata":{"id":"6e5qWLRRucaO","colab_type":"code","colab":{}},"source":["test_ratings = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)] \n","\n","test_file = urllib.request.urlopen(\"https://drive.google.com/uc?export=view&id=1LBgTF57DD2NA-petq_FaC1V-h7nrYIh9\")\n","for line in test_file:\n","  [u, i, rating] = line.decode(\"utf-8\").split(\"::\")\n","  test_ratings[int(u)][int(i)] = int(rating)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YpG1RK15uld0","colab_type":"text"},"source":["## Entrenamiento del modelo\n","\n","Veamos cómo podemos aplicar las fórmulas anteriores para entrenar el modelo.\n"]},{"cell_type":"markdown","metadata":{"id":"iSb2-aXCurQy","colab_type":"text"},"source":["Primero, definimos los parámetros del modelo:"]},{"cell_type":"code","metadata":{"id":"T-V28H_juQ-X","colab_type":"code","colab":{}},"source":["NUM_FACTORS = 5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5FV38gxWuQ-Z","colab_type":"text"},"source":["Inicializamos los factores $w_u$ y $h_i$ con valores uniformes aleatorios en el intervalo \\[0, 1]."]},{"cell_type":"code","metadata":{"id":"7wCL1avRuQ-a","colab_type":"code","colab":{}},"source":["w = [[random.random() for _ in range(NUM_FACTORS)] for _ in range(NUM_USERS)] \n","h = [[random.random() for _ in range(NUM_FACTORS)] for _ in range(NUM_ITEMS)] "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PZkbguNUuonv","colab_type":"text"},"source":["Previo al entrenamiento del modelo, definimos una función que nos permite calcular las predicciones del mismo:"]},{"cell_type":"code","metadata":{"id":"ZbgKUe0GuvHj","colab_type":"code","colab":{}},"source":["def compute_prediction (w_u, h_i):\n","  prediction = 0\n","  for k in range(NUM_FACTORS):\n","    prediction += w_u[k] * h_i[k]\n","  return prediction"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EWJUu6UAuQ-b","colab_type":"text"},"source":["Vamos a hacer que el modelo aprenda. Ejecutamos tantas veces como iteraciones haya la actualización de los factores. Para ello, recorremos el conjunto de votos y vamos haciendo las actualizaciones correspondientes."]},{"cell_type":"code","metadata":{"id":"1Q21B9BQWIGS","colab_type":"code","colab":{}},"source":["NUM_ITERATIONS = 5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wqfRa1ThuQ-c","colab_type":"code","outputId":"3e81a5ee-3ba9-44e1-fd08-0fad28ae06e8","executionInfo":{"status":"ok","timestamp":1556535782687,"user_tz":-120,"elapsed":20951,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh5.googleusercontent.com/-t9XtZoyOrPU/AAAAAAAAAAI/AAAAAAAAA2I/muQCKCLOQqk/s64/photo.jpg","userId":"02003917424124170753"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["for it in range(NUM_ITERATIONS):\n","  print(\"Iteración \" + str(it + 1) + \" de \" + str(NUM_ITERATIONS))\n","  \n","  # Actualizamos w fijando h\n","  \n","  for u in range(NUM_USERS):\n","    \n","    predictions = [None] * NUM_ITEMS\n","    \n","    for i in range(NUM_ITEMS):\n","        if ratings[u][i] != None:\n","          predictions[i] = compute_prediction(w[u], h[i])\n","    \n","    \n","    for k in range(NUM_FACTORS):\n","      \n","      sum_ratings = 0\n","      sum_predictions = 1e-10\n","      \n","      for i in range(NUM_ITEMS):\n","        if ratings[u][i] != None:\n","          \n","          sum_ratings += h[i][k] * ratings[u][i]\n","          sum_predictions += h[i][k] * predictions[i]\n","          \n","      w[u][k] = w[u][k] * sum_ratings / sum_predictions\n","          \n","    \n","  # Actualizamos h fijando w\n","  \n","  for i in range(NUM_ITEMS):\n","    \n","    predictions = [None] * NUM_USERS\n","    \n","    for u in range(NUM_USERS):\n","      if ratings[u][i] != None:\n","          predictions[u] = compute_prediction(w[u], h[i])\n","  \n","    for k in range(NUM_FACTORS):\n","      \n","      sum_ratings = 0\n","      sum_predictions = 1e-10\n","      \n","      for u in range(NUM_USERS):\n","        if ratings[u][i] != None:\n","          \n","          sum_ratings += w[u][k] * ratings[u][i]\n","          sum_predictions += w[u][k] * predictions[u]\n","          \n","      h[i][k] = h[i][k] * sum_ratings / sum_predictions"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Iteración 1 de 5\n","Iteración 2 de 5\n","Iteración 3 de 5\n","Iteración 4 de 5\n","Iteración 5 de 5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Kdp0NTnLwPPP"},"source":["## Cálculo de las predicciones\n","\n","Como hemos comentado, calcular la predicción del voto del usuario *u* al item *i* implicar realizar el producto escalar de sus vectores de factores. Esta operación ha sido definida previamente.\n"]},{"cell_type":"markdown","metadata":{"id":"RwLhJQRcLT0A","colab_type":"text"},"source":["## Cálculo de las recomendaciones\n","\n","El cálculo de las recomendaciones, por lo general, simplemente implica seleccionar los *N* items con una predicción más alta. Por ejemplo, si quisiéramos recomendar *N = 3* items a un usuario que tuviera las siguientes predicciones:\n","\n","|   \t| i1 \t| i2 \t| i3 \t| i4 \t| i5 \t| i6 \t| i7 \t| i8 \t| i9 \t| i10 \t|\n","|:-:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|:--:\t|-----\t|\n","| u \t|   \t|  2,9 \t|    \t|  4,7 \t|  5,0 \t|    \t|  1,2 \t|    \t|   \t|  3,1 \t|\n","\n","Se le recomendarían a dicho usuario los items *i5*, *i4* e *i10*.\n"]},{"cell_type":"markdown","metadata":{"id":"d25K5LZ8UqZE","colab_type":"text"},"source":["##Cálculo del MAE\n","\n","En esta sección vamos a mostrar cómo calcular el error medio absoluto (MAE) de las predicciones realizadas por el algoritmo NMF.\n","\n","Para ello, lo primero que debemos hacer es calcular las predicciones para todos los items que haya recibido una votación de test:"]},{"cell_type":"code","metadata":{"id":"EOx7B3rwUu0i","colab_type":"code","colab":{}},"source":["predictions = [[None for _ in range(NUM_ITEMS)] for _ in range(NUM_USERS)] \n","\n","for u in range(NUM_USERS):\n","  for i in range(NUM_ITEMS):\n","    if test_ratings[u][i] != None:\n","      predictions[u][i] = compute_prediction(w[u], h[i])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3DROA4nXUz2M","colab_type":"text"},"source":["Y, a continuación, calculamos el MAE:"]},{"cell_type":"code","metadata":{"id":"VaSDJhw1U1sM","colab_type":"code","colab":{}},"source":["def get_user_mae (u):\n","  mae = 0\n","  count = 0\n","  \n","  for i in range(NUM_ITEMS):\n","    if test_ratings[u][i] != None and predictions[u][i] != None:\n","      mae += abs(test_ratings[u][i] - predictions[u][i])\n","      count += 1\n","  \n","  if count > 0:\n","    return mae / count\n","  else:\n","    return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYi711CXU4TB","colab_type":"code","colab":{}},"source":["def get_mae ():\n","  mae = 0\n","  count = 0\n","  \n","  for u in range(NUM_USERS):\n","    user_mae = get_user_mae(u)\n","      \n","    if user_mae != None:\n","      mae += user_mae\n","      count += 1\n","  \n","  \n","  if count > 0:\n","    return mae / count\n","  else:\n","    return None   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EcdujGunU569","colab_type":"code","outputId":"599c6260-219a-44ab-caf5-03b12a894e89","executionInfo":{"status":"ok","timestamp":1556535783254,"user_tz":-120,"elapsed":21481,"user":{"displayName":"Fernando Ortega Requena","photoUrl":"https://lh5.googleusercontent.com/-t9XtZoyOrPU/AAAAAAAAAAI/AAAAAAAAA2I/muQCKCLOQqk/s64/photo.jpg","userId":"02003917424124170753"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mae = get_mae()\n","print(\"System MAE = \" + str(mae))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["System MAE = 0.8592044293164004\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y9osKwwRViU7","colab_type":"text"},"source":["## Referencias\n","\n","Lee, D. D., & Seung, H. S. (2001). **Algorithms for non-negative matrix factorization**. In Advances in neural information processing systems (pp. 556-562).\n"]},{"cell_type":"markdown","metadata":{"id":"N3F5dIirf1EQ","colab_type":"text"},"source":["---\n","\n","*Este documento ha sido desarrollado por **Fernando Ortega**. Dpto. Sistemas Informáticos, ETSI de Sistemas Informáticos, Universidad Politécnica de Madrid.*\n","\n","*Última actualización: Abril de 2019*\n"]},{"cell_type":"markdown","metadata":{"id":"vYyz6qfH_AUm","colab_type":"text"},"source":["<img src=\"https://drive.google.com/uc?export=view&id=1QuQDHyH_yrRbNt6sGzoZ8YcvFGEGlnWZ\" alt=\"CC BY-NC\">"]}]}